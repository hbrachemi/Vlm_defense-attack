{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740e1e4-08ba-45f9-93cd-59de50420d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImageNet import *\n",
    "\n",
    "db_path = \"/data/lab_ietr/hbrachem/ImageNet/\"\n",
    "dataset = ImageNet_dataset(os.path.join(db_path,\"serialized_val.pickle\"),db_path=os.path.join(db_path,\"ILSVRC/Data/CLS-LOC/val/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b60d68-365e-4c91-8288-c525206607e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import *\n",
    "\n",
    "vlm = 'Llava-7b'\n",
    "model,processor = vlm_pretrained(vlm)\n",
    "device = model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2acb2-0b74-4290-892a-697b004598bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_QKV(vlm,model)\n",
    "w = processor.image_processor.crop_size['width']\n",
    "h = processor.image_processor.crop_size['height']\n",
    "patch_dim = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50dc2a3-970f-4022-a59c-83738a288bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targeted_layer = 2\n",
    "\n",
    "attack_config = {\n",
    "    'lr':\"1e-3\",\n",
    "    'component': 'encoder',\n",
    "    'layers':f\"{num_targeted_layer}F\",\n",
    "    'bounding_box':'scaled*336',\n",
    "    'algo':  \"min_att\",\n",
    "    'loss':\"att_mean\",\n",
    "    'optimizer':'adam',\n",
    "    'steps':1000,\n",
    "    'checkpoint':250,\n",
    "}\n",
    "\n",
    "target_layers_v = encoder[\"V\"][:num_targeted_layer]\n",
    "target_layers_k = encoder[\"K\"][:num_targeted_layer]\n",
    "target_layers_q = encoder[\"Q\"][:num_targeted_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa8da7-69f2-4135-b1e3-ab58dbb628dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"ablation_study/llava_{attack_config['component']}_{attack_config['layers']}/algo_{attack_config['algo']}/{attack_config['loss']}/{attack_config['optimizer']}_{attack_config['lr']}\"\n",
    "\n",
    "!mkdir -p $path\n",
    "folder = path+'/adv_img'\n",
    "!mkdir $folder\n",
    "folder = path+'/hist'\n",
    "!mkdir $folder\n",
    "folder = path+'/predictions'\n",
    "!mkdir $folder\n",
    "folder = path+'/best'\n",
    "!mkdir $folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcd552-e41b-48f7-a191-f9d52fa30b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb10b6c-d454-4139-ba55-6f5515a9dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2954b-243b-47e4-95ca-8f20846a566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ,[image,label,boxes,img_name] in enumerate(dataset):\n",
    "    print(f\"Processing sample number {i}...\")\n",
    "    if i == 50:\n",
    "        break\n",
    "        \n",
    "    image = image.convert('RGB').resize((w,h))\n",
    "    ref = np.array(image.convert('RGB')).copy()\n",
    "    boxes = bounding_box_new_position(image,boxes,w,h)\n",
    "\n",
    "    parametters = {'image':image}\n",
    "    parametters['label'] = label\n",
    "    parametters['boxes'] = boxes\n",
    "    parametters['model'] = model\n",
    "    parametters['processor'] = processor\n",
    "    parametters['optimizer'] = attack_config[\"optimizer\"]\n",
    "    parametters['lr'] = float(attack_config['lr'])\n",
    "    parametters['target_layers_q'] = target_layers_q\n",
    "    parametters['target_layers_k'] = target_layers_k\n",
    "    parametters['target_layers_v'] = target_layers_v\n",
    "    parametters['lambda_a'] = 1\n",
    "    parametters['lambda_e'] = 0\n",
    "    parametters['lambda_n'] = 0\n",
    "    parametters['w'] = w\n",
    "    parametters['h'] = h\n",
    "    parametters['patch_dim'] = patch_dim\n",
    "    parametters['steps'] = attack_config[\"steps\"]\n",
    "    parametters['checkpoint'] = attack_config[\"checkpoint\"]\n",
    "    parametters['path'] = path\n",
    "    parametters['img_name'] = img_name\n",
    "    \n",
    "    best_image, exec_time = generate_adv_image(**parametters)\n",
    "\n",
    "    print(f\"execution_time: {exec_time}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83340aaa-3131-4978-9f6e-e9dbde095979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b16c7-6d8f-4897-84ac-d7bc49dc81e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493fc26-bd43-4ae6-ba4a-ef0817897b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
